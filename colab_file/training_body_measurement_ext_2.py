# -*- coding: utf-8 -*-
"""Training Body Measurement ext 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rhLJkmXgESL1i_AG9hEbsti0F14XgwB8
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import transforms, models
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, Subset
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error
import os
import time
from PIL import Image
import random
import cv2
from torch.cuda.amp import autocast, GradScaler
from google.colab import drive
from tqdm import tqdm
from functools import lru_cache
from torch.optim.lr_scheduler import ReduceLROnPlateau
import csv
from PIL import Image, ImageDraw
from scipy.spatial import ConvexHull
!pip install chumpy
from torch.optim import Adam

from functools import lru_cache

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Mount Google Drive
drive.mount('/content/drive')

# Load and preprocess data
def load_and_preprocess_data(csv_path):
    merged_measures = pd.read_csv(csv_path)
    print("Missing entries:")
    print(merged_measures.isnull().sum())

    measurement_float = ['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'height', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'height_cm', 'weight_kg']
    for col in measurement_float:
        merged_measures[col] = pd.to_numeric(merged_measures[col], errors='coerce')

    print("NaN values after conversion:")
    print(merged_measures.isna().sum())

    merged_measures['gender'] = merged_measures['gender'].map({'male': 0, 'female': 1}).astype(int)

    return merged_measures, measurement_float

def load_phone_dimensions(csv_file):
    try:
        df = pd.read_csv(csv_file)
        print(df.head())

        # Ensure all required columns are present
        required_columns = ['Brand', 'Model', 'Height']
        for col in required_columns:
            if col not in df.columns:
                raise KeyError(f"Required column '{col}' not found in the CSV file.")

        # Combine 'Brand' and 'Model' columns
        df['Brand Model'] = df['Brand'] + ' ' + df['Model']

        # Convert dimensions to float, just in case
        df['Height'] = df['Height'].astype(float)

        # If 'Width' and 'Depth' are not present, use 'Height' as a substitute
        if 'Width' not in df.columns:
            df['Width'] = df['Height']
        if 'Depth' not in df.columns:
            df['Depth'] = df['Height']

        # Create a list of tuples with the required information
        phone_dimensions = list(zip(df['Brand Model'], df['Height'], df['Width'], df['Depth']))
        print(f"Loaded {len(phone_dimensions)} valid phone dimensions.")
        print("First few entries:")
        for dim in phone_dimensions[:5]:
            print(dim)
        return phone_dimensions

    except Exception as e:
        print(f"Error loading or processing {csv_file}: {str(e)}")
        return []

# Global variable for phone dimensions
phone_dimensions = load_phone_dimensions('/content/drive/MyDrive/bodymeasurement/train/mobile_cleaned_extended_no_nan.csv')
if not phone_dimensions:
    print("Warning: No valid phone dimensions loaded. Using default values.")
    phone_dimensions = [('Default', 150.0, 75.0, 8.0)]

class ConcatenatedImageDataset(Dataset):
    def __init__(self, front_img_dir, side_img_dir, measurement_df, measurement_float, transform=None, cache_size=1000):
        self.front_img_dir = front_img_dir
        self.side_img_dir = side_img_dir
        self.measurements = measurement_df
        self.measurement_float = measurement_float
        self.transform = transform
        self.cache = {}
        self.phone_dimensions = phone_dimensions

        # Save sample images during initialization
        self.save_sample_images(num_samples=20)

    def __len__(self):
        return len(self.measurements)

    def __getitem__(self, idx):
        max_attempts = 5
        for _ in range(max_attempts):
            try:
                if idx in self.cache:
                    concatenated_image, phone_info, weight = self.cache[idx]
                else:
                    photo_id = self.measurements.iloc[idx]['photo_id']
                    result = self.process_image(idx, photo_id)
                    if result[0] is None:
                        continue
                    self.cache[idx] = result
                    concatenated_image, phone_info, weight = result

                if self.transform:
                    concatenated_image = self.transform(concatenated_image)

                # Get measurements excluding height_cm
                targets = torch.tensor([
                    self.measurements.iloc[idx][col]
                    for col in self.measurement_float
                    if col not in ['height_cm']
                ], dtype=torch.float32)

                weight_target = torch.tensor(self.measurements.iloc[idx]['weight_kg'], dtype=torch.float32)
                gender = torch.tensor(self.measurements.iloc[idx]['gender'], dtype=torch.float32)

                return concatenated_image, targets, gender, phone_info, weight_target
            except Exception as e:
                idx = (idx + 1) % len(self)

        raise RuntimeError("Failed to fetch valid data after multiple attempts")

    def process_image(self, idx, photo_id):
        try:
            # Load and process images
            front_image = Image.open(os.path.join(self.front_img_dir, f"{photo_id}.png")).convert('RGB')
            side_image = Image.open(os.path.join(self.side_img_dir, f"{photo_id}.png")).convert('RGB')

            if front_image.size != side_image.size:
                return None, None, None

            # Find person bounds
            front_bounds = self.find_person_bounds(front_image)
            side_bounds = self.find_person_bounds(side_image)
            if None in [front_bounds, side_bounds]:
                return None, None, None

            # Crop images
            front_cropped = front_image.crop(front_bounds)
            side_cropped = side_image.crop(side_bounds)

            # Get person measurements
            person_height_cm = self.measurements.iloc[idx]['height_cm']
            person_weight_kg = self.measurements.iloc[idx]['weight_kg']

            # Generate phone parameters
            phone_params = self.generate_phone_params(front_cropped.size[1], person_height_cm)
            if phone_params is None:
                return None, None, None

            # Unpack phone parameters
            _, phone_length_mm, phone_width_mm, phone_depth_mm, front_rect, side_rect = phone_params

            # Add phone rectangles to images
            front_cropped = self.add_rectangle_to_image(front_cropped, front_rect)
            side_cropped = self.add_rectangle_to_image(side_cropped, side_rect)

            # Resize with padding and get metadata
            front_padded, front_resized_dims, front_paste = self.resize_with_padding(front_cropped, (480, 640))
            side_padded, side_resized_dims, side_paste = self.resize_with_padding(side_cropped, (480, 640))

            # Create concatenated image
            concatenated_image = Image.new('RGB', (960, 640))
            concatenated_image.paste(front_padded, (0, 0))
            concatenated_image.paste(side_padded, (480, 0))

            # Scale coordinates with padding correction
            scaled_front_rect = self.scale_coordinates(
                front_rect,
                (front_cropped.width, front_cropped.height),
                front_resized_dims,
                front_paste
            )

            scaled_side_rect = self.scale_coordinates(
                side_rect,
                (side_cropped.width, side_cropped.height),
                side_resized_dims,
                side_paste
            )

            # Adjust side view coordinates for concatenated image
            scaled_side_rect = [x + 480 if i % 2 == 0 else x for i, x in enumerate(scaled_side_rect)]

            # Create phone info tensor (convert mm to cm)
            phone_info = torch.tensor([
                phone_length_mm / 10.0,
                phone_width_mm / 10.0,
                phone_depth_mm / 10.0,
                *scaled_front_rect,
                *scaled_side_rect
            ], dtype=torch.float32)

            return concatenated_image, phone_info, person_weight_kg

        except Exception as e:
            print(f"Error in process_image: {str(e)}")
            return None, None, None

    def generate_phone_params(self, image_height, person_height_cm):
        try:
            # Select random phone dimensions (model, length, width, depth in mm)
            phone_model, length_mm, width_mm, depth_mm = random.choice(self.phone_dimensions)

            # Calculate pixel-to-mm ratio based on person height
            pixels_per_mm = image_height / (person_height_cm * 10)

            # Calculate phone dimensions in pixels
            phone_height_px = int(length_mm * pixels_per_mm)
            phone_width_px = int(width_mm * pixels_per_mm)
            phone_depth_px = int(depth_mm * pixels_per_mm)

            # Generate random positions (50-70% of image height)
            min_y = int(image_height * 0.5)
            max_y = int(image_height * 0.7) - phone_height_px

            # Front view rectangle (width x height)
            front_y = random.randint(min_y, max_y)
            front_x = random.randint(0, 480 - phone_width_px)

            # Side view rectangle (depth x height)
            side_y = random.randint(min_y, max_y)
            side_x = random.randint(0, 480 - phone_depth_px)

            return (
                phone_model,
                length_mm,
                width_mm,
                depth_mm,
                (front_x, front_y, front_x + phone_width_px, front_y + phone_height_px),
                (side_x, side_y, side_x + phone_depth_px, side_y + phone_height_px)
            )
        except Exception as e:
            print(f"Error generating phone params: {str(e)}")
            return None

    def save_sample_images(self, num_samples=20):
        print(f"Saving {num_samples} sample images...")
        save_dir = '/content/drive/MyDrive/bodymeasurement/train/processed_samples5'
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        idx = 0
        saved_count = 0
        while saved_count < num_samples and idx < len(self):
            try:
                photo_id = self.measurements.iloc[idx]['photo_id']
                concatenated_image, phone_info, weight = self.process_image(idx, photo_id)

                if concatenated_image is not None:
                    # Save the image
                    save_path = os.path.join(save_dir, f'sample_{saved_count}_photo_{photo_id}.png')
                    concatenated_image.save(save_path)

                    # Save the phone info for verification
                    info_path = os.path.join(save_dir, f'sample_{saved_count}_photo_{photo_id}_info.txt')
                    with open(info_path, 'w') as f:
                        f.write(f"Phone dimensions (mm): length={phone_info[0]}, width={phone_info[1]}, depth={phone_info[2]}\n")
                        f.write(f"Front rectangle: {phone_info[3:7].tolist()}\n")
                        f.write(f"Side rectangle: {phone_info[7:].tolist()}\n")

                    saved_count += 1
                    print(f"Saved sample {saved_count}/{num_samples}")

                idx += 1
            except Exception as e:
                print(f"Error saving sample {idx}: {str(e)}")
                idx += 1

        print(f"Successfully saved {saved_count} sample images to {save_dir}")

    @staticmethod
    def find_person_bounds(image):
        # Convert to numpy array for processing
        img_array = np.array(image)

        # Find non-black pixels
        non_black = np.any(img_array != 0, axis=2)
        rows = np.any(non_black, axis=1)
        cols = np.any(non_black, axis=0)

        if not np.any(rows) or not np.any(cols):
            return None

        ymin, ymax = np.where(rows)[0][[0, -1]]
        xmin, xmax = np.where(cols)[0][[0, -1]]

        # Add padding to bounds
        padding = 10
        ymin = max(0, ymin - padding)
        ymax = min(image.size[1], ymax + padding)
        xmin = max(0, xmin - padding)
        xmax = min(image.size[0], xmax + padding)

        return (xmin, ymin, xmax, ymax)

    @staticmethod
    def add_rectangle_to_image(image, rectangle_coords):
        draw = ImageDraw.Draw(image)
        draw.rectangle(rectangle_coords, outline=(0, 0, 255), width=2)
        return image

    @staticmethod
    def resize_with_padding(image, target_size):
        original_width, original_height = image.size
        target_width, target_height = target_size

        # Calculate new dimensions
        ratio = min(target_width/original_width, target_height/original_height)
        new_width = int(original_width * ratio)
        new_height = int(original_height * ratio)

        # Resize image
        resized = image.resize((new_width, new_height), Image.Resampling.LANCZOS)

        # Calculate padding
        paste_x = (target_width - new_width) // 2
        paste_y = (target_height - new_height) // 2

        # Create padded image
        padded = Image.new('RGB', target_size, (0, 0, 0))
        padded.paste(resized, (paste_x, paste_y))

        return padded, (new_width, new_height), (paste_x, paste_y)

    @staticmethod
    def scale_coordinates(rect, original_size, resized_dims, paste_coords):
        """
        rect: (x1, y1, x2, y2) in original image coordinates
        original_size: (width, height) of original image
        resized_dims: (width, height) of resized image before padding
        paste_coords: (x, y) where resized image was pasted
        """
        # Calculate scale factors
        scale_w = resized_dims[0] / original_size[0]
        scale_h = resized_dims[1] / original_size[1]

        # Scale coordinates
        scaled = [
            rect[0] * scale_w,
            rect[1] * scale_h,
            rect[2] * scale_w,
            rect[3] * scale_h
        ]

        # Apply padding offsets
        return [
            scaled[0] + paste_coords[0],
            scaled[1] + paste_coords[1],
            scaled[2] + paste_coords[0],
            scaled[3] + paste_coords[1]
        ]

#the custom_collate function here
def custom_collate(batch):
    batch = list(filter(lambda x: x is not None, batch))
    return torch.utils.data.dataloader.default_collate(batch)

# Prepare dataset
def prepare_dataset(front_img_dir, side_img_dir, measurement_df, measurement_float, processed_dir):
    dataset = ConcatenatedImageDataset(front_img_dir, side_img_dir, measurement_df, measurement_float, processed_dir=processed_dir)
    print(f"Preparing dataset with {len(dataset)} images")
    for i in tqdm(range(len(dataset)), desc="Processing images"):
        _ = dataset[i]  # This will process and save all images
    print("Dataset preparation complete")
    return dataset

# Model definition
class EnhancedResNet101(nn.Module):
    def __init__(self, measurement_float):
        super().__init__()
        self.base_model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V2)
        self.features = nn.Sequential(*list(self.base_model.children())[:-1])

        # Additional features
        self.num_phone_dims = 3  # length, width, width
        self.num_front_rect = 4
        self.num_side_rect = 4
        self.num_gender = 1

        total_additional_features = (self.num_phone_dims +
                                   self.num_front_rect +
                                   self.num_side_rect +
                                   self.num_gender)

        # Intermediate layers
        self.fc1 = nn.Linear(self.base_model.fc.in_features + total_additional_features, 1024)
        self.bn1 = nn.BatchNorm1d(1024)
        self.dropout1 = nn.Dropout(0.3)

        self.fc2 = nn.Linear(1024, 512)
        self.bn2 = nn.BatchNorm1d(512)
        self.dropout2 = nn.Dropout(0.3)

        pred_measurements = [m for m in measurement_float if m not in ['height_cm']]

        # Separate output layers for measurements and weight
        self.measurements_fc = nn.Linear(512, len(pred_measurements))
        self.weight_fc = nn.Linear(512, 1)  # Separate layer for weight prediction

        self.pred_measurements = pred_measurements

        self.measurement_names = measurement_float

    def forward(self, x, phone_info, gender):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = torch.cat([x, phone_info, gender.unsqueeze(1)], dim=1)

        x = self.dropout1(self.bn1(F.relu(self.fc1(x))))
        x = self.dropout2(self.bn2(F.relu(self.fc2(x))))

        measurements = self.measurements_fc(x)
        weight = self.weight_fc(x)

        return measurements, weight.squeeze(1)

def get_optimizer(model):
    # Group parameters by layer type
    backbone_params = []
    head_params = []

    # Backbone (ResNet) parameters
    for name, param in model.features.named_parameters():
        backbone_params.append(param)

    # Head (FC layers) parameters
    head_params = (
        list(model.fc1.parameters()) +
        list(model.bn1.parameters()) +
        list(model.fc2.parameters()) +
        list(model.bn2.parameters()) +
        list(model.measurements_fc.parameters()) +
        list(model.weight_fc.parameters())  # Include weight prediction layer
    )

    # Create optimizer with different learning rates
    optimizer = optim.Adam([
        {'params': backbone_params, 'lr': 1e-5},  # Slower learning for pretrained layers
        {'params': head_params, 'lr': 5e-4}       # Faster learning for new layers
    ], weight_decay=0.0001)

    return optimizer

class WeightedMeasurementLoss(nn.Module):
    def __init__(self, measurement_names):
        super().__init__()
        self.weights = {
            'height': 0.1,
            'shoulder-breadth': 0.5,
            'chest': 0.3,
            'waist': 0.3,
            'hip': 0.3,
            'leg-length': 0.2,
            'arm-length': 0.5,
            'shoulder-to-crotch': 0.5,
            'thigh': 0.8,
            'bicep': 1.0,
            'forearm': 1.0,
            'wrist': 1.2,
            'calf': 1.0,
            'ankle': 1.2,
            'weight_kg': 0.4  # Added weight prediction weight
        }
        self.measurement_names = measurement_names

    def forward(self, predictions, weight_pred, targets, weight_target):
        # Handle measurements loss
        measurement_loss = 0
        for i, name in enumerate(self.measurement_names):
            if name in self.weights:
                weight = self.weights.get(name, 1.0)
                measure_loss = F.l1_loss(predictions[:, i], targets[:, i])
                measurement_loss += weight * measure_loss

        # Handle weight prediction loss
        weight_loss = self.weights['weight_kg'] * F.l1_loss(weight_pred, weight_target)

        # Combine losses
        total_loss = (measurement_loss + weight_loss) / (len(self.measurement_names) + 1)
        return total_loss

class MeasurementNormalizer:
    def __init__(self, measurement_df, measurement_names):
        self.means = {}
        self.stds = {}
        # Initialize for all measurements
        for name in measurement_names:
            self.means[name] = measurement_df[name].mean()
            self.stds[name] = measurement_df[name].std()

    def normalize(self, data, measurement_names):
        normalized = torch.zeros_like(data)
        for i, name in enumerate(measurement_names):
            normalized[:, i] = (data[:, i] - self.means[name]) / self.stds[name]
        return normalized

    def denormalize(self, normalized_data, measurement_names):
        denormalized = torch.zeros_like(normalized_data)
        for i, name in enumerate(measurement_names):
            denormalized[:, i] = normalized_data[:, i] * self.stds[name] + self.means[name]
        return denormalized

def train_and_evaluate(model, train_loader, test_loader, measurement_float, train_measurement_df, save_dir='/content/drive/MyDrive/bodymeasurement/train/checkpoints_adv5', accumulation_steps=4, resume=False, epochs=200):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # Initialize optimizer, loss functions, and normalizer
    optimizer = get_optimizer(model)
    #pred_measurements = [m for m in measurement_float if m not in ['height_cm', 'weight_kg']]
    pred_measurements = model.pred_measurements
    weighted_loss = WeightedMeasurementLoss(pred_measurements)
    normalizer = MeasurementNormalizer(train_measurement_df, pred_measurements)

    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    log_file = os.path.join(save_dir, 'training_log.csv')
    log_exists = os.path.exists(log_file)

    best_mae = float('inf')
    start_epoch = 0

    checkpoint_path = os.path.join(save_dir, 'latest_checkpoint.pth')
    if resume and os.path.exists(checkpoint_path):
        print("Loading checkpoint...")
        checkpoint = torch.load(checkpoint_path)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_mae = checkpoint['best_mae']
        print(f"Resuming from epoch {start_epoch}")
    else:
        print("Starting training from scratch.")

    print("Starting training...")
    with open(log_file, 'a', newline='') as f:
        writer = csv.writer(f)
        if not log_exists:
            writer.writerow(['Epoch', 'Train Loss', 'Train MAE', 'Test MAE', 'Time'])

        for epoch in range(start_epoch, epochs):
            start_time = time.time()
            model.train()
            train_loss = 0.0
            train_mae = 0.0
            train_measurements_mae = 0.0  # Initialize train_measurements_mae here
            train_weight_mae = 0.0  # Initialize train_weight_mae here
            optimizer.zero_grad()

            for batch_idx, (inputs, targets, gender, phone_info, weight_target) in enumerate(tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")):
                inputs = inputs.to(device)
                targets = targets.to(device)
                gender = gender.to(device)
                phone_info = phone_info.to(device)
                weight_target = weight_target.to(device)

                # Normalize targets
                #normalized_targets = normalizer.normalize(targets, [m for m in measurement_float if m not in ['height_cm', 'weight_kg']])
                normalized_targets = normalizer.normalize(targets, pred_measurements) #check for potential errors
                outputs_measurements, outputs_weight = model(inputs, phone_info, gender)

                loss = weighted_loss(outputs_measurements,outputs_weight, normalized_targets, weight_target)
                loss = loss / accumulation_steps
                loss.backward()

                if (batch_idx + 1) % accumulation_steps == 0 or batch_idx + 1 == len(train_loader):
                    optimizer.step()
                    optimizer.zero_grad()

                # Denormalize for MAE calculation
                denormalized_outputs = normalizer.denormalize(outputs_measurements, pred_measurements)
                train_loss += loss.item() * accumulation_steps
                train_mae += F.l1_loss(denormalized_outputs, targets[:, :len(pred_measurements)]).item() * accumulation_steps

                # Calculate separate MAEs for measurements and weight
                train_measurements_mae += F.l1_loss(denormalized_outputs, targets[:, :len(pred_measurements)]).item() * accumulation_steps
                train_weight_mae += F.l1_loss(outputs_weight, weight_target).item() * accumulation_steps


            avg_train_loss = train_loss / len(train_loader)
            avg_train_mae = train_mae / len(train_loader)

            model.eval()
            test_mae = 0.0
            test_weight_mae = 0.0
            test_measurements_mae = 0.0  # Initialize test_measurements_mae here

            with torch.no_grad():
                for inputs, targets, gender, phone_info, weight_target in tqdm(test_loader, desc="Evaluating"):
                    inputs = inputs.to(device)
                    targets = targets.to(device)
                    gender = gender.to(device)
                    phone_info = phone_info.to(device)
                    weight_target = weight_target.to(device)

                    outputs_measurement, outputs_weight = model(inputs, phone_info, gender)
                    denormalized_outputs = normalizer.denormalize(outputs_measurement, pred_measurements)
                    test_mae += F.l1_loss(denormalized_outputs, targets[:, :len(pred_measurements)]).item()

                    #calculate and accumumate weight MAE for the batch

                    # Calculate separate MAEs for measurements and weight
                    test_measurements_mae += F.l1_loss(denormalized_outputs, targets[:, :len(pred_measurements)]).item()
                    test_weight_mae += F.l1_loss(outputs_weight, weight_target).item()

                    avg_test_weight_mae = test_weight_mae / len(test_loader)

            current_test_mae = test_mae / len(test_loader)
            epoch_time = time.time() - start_time

            print(f"Epoch {epoch+1}/{epochs}")
            print(f"Train Loss: {avg_train_loss:.4f}, Train MAE: {avg_train_mae:.4f}, Test MAE: {current_test_mae:.4f}")
            print(f"Time: {epoch_time:.2f}s")

            print(f"Weight MAE: {avg_test_weight_mae:.4f}")

            # Log results
            writer.writerow([epoch+1, avg_train_loss, avg_train_mae, current_test_mae, epoch_time])
            f.flush()

            if current_test_mae < best_mae:
                best_mae = current_test_mae
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_mae': best_mae,
                }, os.path.join(save_dir, 'best_model.pth'))
                print(f"New best model saved with MAE: {best_mae:.4f}")

            if (epoch + 1) % 10 == 0:
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_mae': best_mae,
                }, checkpoint_path)
                print(f"Checkpoint saved at epoch {epoch + 1}")

    return best_mae

# Main execution
if __name__ == "__main__":
    # Set device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load and preprocess data
    train_measurement_df, measurement_float = load_and_preprocess_data('/content/drive/MyDrive/bodymeasurement/train/merged_measurements.csv')
    test_measurement_df, _ = load_and_preprocess_data('/content/drive/MyDrive/bodymeasurement/testA/merged_measurements.csv')

    # Define transforms
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    # Load phone dimensions
    phone_dimensions = load_phone_dimensions('/content/drive/MyDrive/bodymeasurement/train/mobile_cleaned_extended_no_nan.csv')

    if not phone_dimensions:
        print("Warning: No valid phone dimensions loaded. Using default values.")
        phone_dimensions = [('Default', 150.0, 75.0, 8.0)]

    # Create datasets
    train_front_img_dir = '/content/drive/MyDrive/bodymeasurement/train/mask'
    train_side_img_dir = '/content/drive/MyDrive/bodymeasurement/train/mask_left'
    test_front_img_dir = '/content/drive/MyDrive/bodymeasurement/testA/mask'
    test_side_img_dir = '/content/drive/MyDrive/bodymeasurement/testA/mask_left'

    print('Creating datasets.....')
    cache_size = 30000
    train_dataset = ConcatenatedImageDataset(train_front_img_dir, train_side_img_dir, train_measurement_df, measurement_float, transform=transform, cache_size=cache_size)
    test_dataset = ConcatenatedImageDataset(test_front_img_dir, test_side_img_dir, test_measurement_df, measurement_float, transform=transform, cache_size=cache_size)

    # Create data loaders
    print("Creating data loaders...")
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, collate_fn=custom_collate)
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2, collate_fn=custom_collate)

    # Create and train the model
    print("Initializing model...")
    num_measurements = len(measurement_float)
    model  = SwinB384Measure().to(device)
    # Load phone dimensions
    phone_dimensions = load_phone_dimensions('/content/drive/MyDrive/bodymeasurement/train/mobile_cleaned.csv')

# Set up the parameters for training
    lr = 0.0005
    weight_decay = 0.0001
    epochs = 200
    save_dir = '/content/drive/MyDrive/bodymeasurement/train/checkpoints_adv5'
    accumulation_steps = 4

    # Pre-train on real data
    print("Pre-training on real data...")

best_mae = train_and_evaluate(
    model=enhanced_resnet101,
    train_loader=train_loader,
    test_loader=test_loader,
    measurement_float=measurement_float,
    train_measurement_df=train_measurement_df,  # Add this parameter
    save_dir=save_dir,
    accumulation_steps=accumulation_steps,
    resume= True,
    epochs=200
)