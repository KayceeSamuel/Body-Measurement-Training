# -*- coding: utf-8 -*-
"""Body_Measurement_ext.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b0Pzcx-lKYY_p7uvnkkHmytodwFEZk8b
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import transforms, models
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, Subset
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error
import os
import time
from PIL import Image
import random
import cv2
from torch.cuda.amp import autocast, GradScaler
from google.colab import drive
from tqdm import tqdm
from functools import lru_cache
from torch.optim.lr_scheduler import ReduceLROnPlateau
import csv
from PIL import Image, ImageDraw
# !pip install smplx
# import smplx
# from smplx import SMPLX
from scipy.spatial import ConvexHull
!pip install chumpy
from torch.optim import Adam

from functools import lru_cache

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Mount Google Drive
drive.mount('/content/drive')

# Load and preprocess data
def load_and_preprocess_data(csv_path):
    merged_measures = pd.read_csv(csv_path)
    print("Missing entries:")
    print(merged_measures.isnull().sum())

    measurement_float = ['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'height', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'height_cm', 'weight_kg']
    #measurement_float = ['ankle', 'bicep', 'calf', 'chest', 'forearm', 'height', 'hip', 'leg-length', 'shoulder-breadth', 'thigh', 'waist', 'wrist'] #remove the weight to be predicted in a different process
    for col in measurement_float:
        merged_measures[col] = pd.to_numeric(merged_measures[col], errors='coerce')

    print("NaN values after conversion:")
    print(merged_measures.isna().sum())

    merged_measures['gender'] = merged_measures['gender'].map({'male': 0, 'female': 1}).astype(int)

    return merged_measures, measurement_float

def load_phone_dimensions(csv_file):
    try:
        df = pd.read_csv(csv_file)
        # print(f"Successfully loaded {csv_file}")
        # print(f"Columns: {df.columns}")
        print(df.head())

        # Ensure all required columns are present
        required_columns = ['Brand', 'Model', 'Height']
        for col in required_columns:
            if col not in df.columns:
                raise KeyError(f"Required column '{col}' not found in the CSV file.")

        # Combine 'Brand' and 'Model' columns
        df['Brand Model'] = df['Brand'] + ' ' + df['Model']

        # Convert dimensions to float, just in case
        df['Height'] = df['Height'].astype(float)

        # If 'Width' and 'Depth' are not present, use 'Height' as a substitute
        if 'Width' not in df.columns:
            df['Width'] = df['Height']
        if 'Depth' not in df.columns:
            df['Depth'] = df['Height']

        # Create a list of tuples with the required information
        phone_dimensions = list(zip(df['Brand Model'], df['Height'], df['Width'], df['Depth']))

        print(f"Loaded {len(phone_dimensions)} valid phone dimensions.")
        print("First few entries:")
        for dim in phone_dimensions[:5]:
            print(dim)

        return phone_dimensions

    except Exception as e:
        print(f"Error loading or processing {csv_file}: {str(e)}")
        return []

# Global variable for phone dimensions
phone_dimensions = load_phone_dimensions('/content/drive/MyDrive/bodymeasurement/train/mobile_cleaned_extended_no_nan.csv')
if not phone_dimensions:
    print("Warning: No valid phone dimensions loaded. Using default values.")
    phone_dimensions = [('Default', 150.0, 75.0, 8.0)]

# the updated concatenated image
class ConcatenatedImageDataset(Dataset):
    def __init__(self, front_img_dir, side_img_dir, measurement_df, measurement_float, transform=None, cache_size=1000):
        self.front_img_dir = front_img_dir
        self.side_img_dir = side_img_dir
        self.measurements = measurement_df
        self.measurement_float = measurement_float
        self.transform = transform
        self.cache = lru_cache(maxsize=cache_size)(self.process_image)

        # Save sample images during initialization
        self.save_sample_images(num_samples=20)

    def __len__(self):
        return len(self.measurements)

    def __getitem__(self, idx):
        max_attempts = 5
        for _ in range(max_attempts):
            try:
                photo_id = self.measurements.iloc[idx]['photo_id']
                concatenated_image, phone_info = self.cache(idx, photo_id)

                if concatenated_image is None or phone_info is None:
                    idx = (idx + 1) % len(self)
                    continue

                if self.transform:
                    concatenated_image = self.transform(concatenated_image)

                targets = torch.tensor([self.measurements.iloc[idx][col] for col in self.measurement_float if col not in ['height_cm', 'weight_kg']], dtype=torch.float32)
                gender = torch.tensor(self.measurements.iloc[idx]['gender'], dtype=torch.float32)

                return concatenated_image, targets, gender, phone_info
            except Exception as e:
                idx = (idx + 1) % len(self)

        raise RuntimeError("Failed to fetch valid data after multiple attempts")

    def process_image(self, idx, photo_id):
        try:
            # 1. Load original images
            front_image = Image.open(os.path.join(self.front_img_dir, f"{photo_id}.png")).convert('RGB')
            side_image = Image.open(os.path.join(self.side_img_dir, f"{photo_id}.png")).convert('RGB')

            if front_image.size != side_image.size:
                return None, None

            # Get person height for scaling
            person_height_cm = self.measurements.iloc[idx]['height_cm']

            # 2. Generate and add phone rectangles to original images
            phone_params = self.generate_phone_params(front_image.size[1], person_height_cm)
            if phone_params is None:
                return None, None

            _, phone_length_mm, phone_width_mm, phone_depth_mm, front_rect, side_rect = phone_params

            # Add rectangles to original images
            front_image = self.add_rectangle_to_image(front_image, front_rect)
            side_image = self.add_rectangle_to_image(side_image, side_rect)

            # 3. Crop images to person bounds (including phone)
            front_bounds = self.find_person_bounds(front_image)
            side_bounds = self.find_person_bounds(side_image)
            if None in [front_bounds, side_bounds]:
                return None, None

            front_image = front_image.crop(front_bounds)
            side_image = side_image.crop(side_bounds)

            # 4. Resize to (480, 640) maintaining aspect ratio and add padding
            front_image = self.resize_with_padding(front_image, (480, 640))
            side_image = self.resize_with_padding(side_image, (480, 640))

            # 5. Create final concatenated image
            concatenated_image = Image.new('RGB', (960, 640))
            concatenated_image.paste(front_image, (0, 0))
            concatenated_image.paste(side_image, (480, 0))

            # Calculate scaled rectangle coordinates
            scaled_front_rect = self.scale_coordinates(front_rect, front_bounds, (480, 640))
            scaled_side_rect = self.scale_coordinates(side_rect, side_bounds, (480, 640))
            scaled_side_rect = [x + 480 if i % 2 == 0 else x for i, x in enumerate(scaled_side_rect)]

            # Create phone info tensor
            phone_info = torch.tensor([
                phone_length_mm, phone_width_mm, phone_depth_mm,
                *scaled_front_rect,
                *scaled_side_rect
            ], dtype=torch.float32)

            return concatenated_image, phone_info

        except Exception as e:
            return None, None

    def generate_phone_params(self, image_height, person_height_cm):
        try:
            phone_model, phone_length_mm, phone_width_mm, phone_depth_mm = random.choice(phone_dimensions)

            # Convert person height to mm for consistent units
            person_height_mm = person_height_cm * 10

            # Calculate pixel-to-mm ratio based on person height
            pixels_per_mm = image_height / person_height_mm

            # Calculate phone dimensions in pixels
            phone_height_pixels = int(phone_length_mm * pixels_per_mm)
            phone_width_pixels = int(phone_width_mm * pixels_per_mm)
            phone_depth_pixels = int(phone_depth_mm * pixels_per_mm)

            # Generate positions for phone rectangles in lower half of image
            min_y = int(image_height * 0.5)  # Start from middle of image
            max_y = int(image_height * 0.8)  # Don't place too low

            # Front phone rectangle
            front_y = random.randint(min_y, max_y - phone_height_pixels)
            front_x = random.randint(0, 480 - phone_width_pixels)

            # Side phone rectangle
            side_y = random.randint(min_y, max_y - phone_height_pixels)
            side_x = random.randint(0, 480 - phone_depth_pixels)

            return (phone_model,
                   phone_length_mm,
                   phone_width_mm,
                   phone_depth_mm,
                   (front_x, front_y, front_x + phone_width_pixels, front_y + phone_height_pixels),
                   (side_x, side_y, side_x + phone_depth_pixels, side_y + phone_height_pixels))

        except Exception as e:
            return None

    def save_sample_images(self, num_samples=20):
        print(f"Saving {num_samples} sample images...")
        save_dir = '/content/drive/MyDrive/bodymeasurement/train/processed_samples3'
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        idx = 0
        saved_count = 0
        while saved_count < num_samples and idx < len(self):
            try:
                photo_id = self.measurements.iloc[idx]['photo_id']
                concatenated_image, phone_info = self.process_image(idx, photo_id)

                if concatenated_image is not None:
                    # Save the image
                    save_path = os.path.join(save_dir, f'sample_{saved_count}_photo_{photo_id}.png')
                    concatenated_image.save(save_path)

                    # Save the phone info for verification
                    info_path = os.path.join(save_dir, f'sample_{saved_count}_photo_{photo_id}_info.txt')
                    with open(info_path, 'w') as f:
                        f.write(f"Phone dimensions (mm): length={phone_info[0]}, width={phone_info[1]}, depth={phone_info[2]}\n")
                        f.write(f"Front rectangle: {phone_info[3:7].tolist()}\n")
                        f.write(f"Side rectangle: {phone_info[7:].tolist()}\n")

                    saved_count += 1
                    print(f"Saved sample {saved_count}/{num_samples}")

                idx += 1
            except Exception as e:
                print(f"Error saving sample {idx}: {str(e)}")
                idx += 1

        print(f"Successfully saved {saved_count} sample images to {save_dir}")

    @staticmethod
    def find_person_bounds(image):
        # Convert to numpy array for processing
        img_array = np.array(image)

        # Find non-black pixels
        non_black = np.any(img_array != 0, axis=2)
        rows = np.any(non_black, axis=1)
        cols = np.any(non_black, axis=0)

        if not np.any(rows) or not np.any(cols):
            return None

        ymin, ymax = np.where(rows)[0][[0, -1]]
        xmin, xmax = np.where(cols)[0][[0, -1]]

        # Add padding to bounds
        padding = 10
        ymin = max(0, ymin - padding)
        ymax = min(image.size[1], ymax + padding)
        xmin = max(0, xmin - padding)
        xmax = min(image.size[0], xmax + padding)

        return (xmin, ymin, xmax, ymax)

    @staticmethod
    def add_rectangle_to_image(image, rectangle_coords):
        draw = ImageDraw.Draw(image)
        draw.rectangle(rectangle_coords, outline=(0, 0, 255), width=2)
        return image

    @staticmethod
    def resize_with_padding(image, target_size):
        # Calculate aspect ratios
        target_ratio = target_size[0] / target_size[1]
        img_ratio = image.size[0] / image.size[1]

        if img_ratio > target_ratio:
            # Image is wider than target
            new_width = target_size[0]
            new_height = int(new_width / img_ratio)
        else:
            # Image is taller than target
            new_height = target_size[1]
            new_width = int(new_height * img_ratio)

        # Resize image
        resized = image.resize((new_width, new_height), Image.Resampling.LANCZOS)

        # Create new black image and paste resized image
        new_image = Image.new('RGB', target_size, (0, 0, 0))
        paste_x = (target_size[0] - new_width) // 2
        paste_y = (target_size[1] - new_height) // 2
        new_image.paste(resized, (paste_x, paste_y))

        return new_image

    @staticmethod
    def scale_coordinates(rect, bounds, target_size):
        # Adjust coordinates relative to crop bounds
        rel_coords = [
            rect[0] - bounds[0],
            rect[1] - bounds[1],
            rect[2] - bounds[0],
            rect[3] - bounds[1]
        ]

        # Calculate scale factors
        source_width = bounds[2] - bounds[0]
        source_height = bounds[3] - bounds[1]
        scale_x = target_size[0] / source_width
        scale_y = target_size[1] / source_height

        # Scale coordinates
        scaled_coords = [
            rel_coords[0] * scale_x,
            rel_coords[1] * scale_y,
            rel_coords[2] * scale_x,
            rel_coords[3] * scale_y
        ]

        return scaled_coords

#the custom_collate function here
def custom_collate(batch):
    batch = list(filter(lambda x: x is not None, batch))
    return torch.utils.data.dataloader.default_collate(batch)

# Prepare dataset
def prepare_dataset(front_img_dir, side_img_dir, measurement_df, measurement_float, processed_dir):
    dataset = ConcatenatedImageDataset(front_img_dir, side_img_dir, measurement_df, measurement_float, processed_dir=processed_dir)
    print(f"Preparing dataset with {len(dataset)} images")
    for i in tqdm(range(len(dataset)), desc="Processing images"):
        _ = dataset[i]  # This will process and save all images
    print("Dataset preparation complete")
    return dataset

# Model definition
class EnhancedResNet101(nn.Module):
    def __init__(self, measurement_float):
        super().__init__()
        self.base_model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V2)
        self.features = nn.Sequential(*list(self.base_model.children())[:-1])

        # Explicitly define the number of additional features
        self.num_phone_dims = 3  # length, width, depth
        self.num_front_rect = 4  # x1, y1, x2, y2
        self.num_side_rect = 4   # x1, y1, x2, y2
        self.num_gender = 1

        total_additional_features = (self.num_phone_dims +
                                   self.num_front_rect +
                                   self.num_side_rect +
                                   self.num_gender)

        # Add intermediate layers for better feature extraction
        self.fc1 = nn.Linear(self.base_model.fc.in_features + total_additional_features, 1024)
        self.bn1 = nn.BatchNorm1d(1024)
        self.dropout1 = nn.Dropout(0.3)

        self.fc2 = nn.Linear(1024, 512)
        self.bn2 = nn.BatchNorm1d(512)
        self.dropout2 = nn.Dropout(0.3)

        # Final layer for predictions
        self.fc3 = nn.Linear(512, len(measurement_float))

        # Store measurement names for potential use
        self.measurement_names = measurement_float

    def forward(self, x, phone_info, gender):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = torch.cat([x, phone_info, gender.unsqueeze(1)], dim=1)

        # Enhanced feature processing
        x = self.dropout1(self.bn1(F.relu(self.fc1(x))))
        x = self.dropout2(self.bn2(F.relu(self.fc2(x))))
        x = self.fc3(x)

        return x

def get_optimizer(model):
    # Group parameters by layer type
    backbone_params = []
    head_params = []

    # Backbone (ResNet) parameters
    for name, param in model.features.named_parameters():
        backbone_params.append(param)

    # Head (FC layers) parameters
    head_params = (
        list(model.fc1.parameters()) +
        list(model.bn1.parameters()) +
        list(model.fc2.parameters()) +
        list(model.bn2.parameters()) +
        list(model.fc3.parameters())
    )

    # Create optimizer with different learning rates
    optimizer = optim.Adam([
        {'params': backbone_params, 'lr': 1e-5},  # Slower learning for pretrained layers
        {'params': head_params, 'lr': 5e-4}       # Faster learning for new layers
    ], weight_decay=0.0001)

    return optimizer

class WeightedMeasurementLoss(nn.Module):
    def __init__(self, measurement_names):
        super().__init__()
        # Define weights based on typical measurement ranges
        self.weights = {
            'height': 0.1,
            'shoulder-breadth': 0.5,
            'chest': 0.3,
            'waist': 0.3,
            'hip': 0.3,
            'leg-length': 0.2,
            'arm-length': 0.5,
            'shoulder-to-crotch': 0.5,
            'thigh': 0.8,
            'bicep': 1.0,
            'forearm': 1.0,
            'wrist': 1.2,
            'calf': 1.0,
            'ankle': 1.2
        }
        self.measurement_names = measurement_names

    def forward(self, predictions, targets):
        loss = 0
        for i, name in enumerate(self.measurement_names):
            if name in self.weights:
                weight = self.weights.get(name, 1.0)  # Default weight of 1.0 if not specified
                measure_loss = F.l1_loss(predictions[:, i], targets[:, i])
                loss += weight * measure_loss
        return loss / len(self.measurement_names)

class MeasurementNormalizer:
    def __init__(self, measurement_df, measurement_names):
        self.means = {}
        self.stds = {}

        # Calculate mean and std for each measurement
        for name in measurement_names:
            if name not in ['height_cm', 'weight_kg']:
                self.means[name] = measurement_df[name].mean()
                self.stds[name] = measurement_df[name].std()

    def normalize(self, measurements, measurement_names):
        normalized = []
        for i, name in enumerate(measurement_names):
            if name not in ['height_cm', 'weight_kg']:
                normalized.append((measurements[:, i] - self.means[name]) / self.stds[name])
        return torch.stack(normalized, dim=1)

    def denormalize(self, normalized_measurements, measurement_names):
        denormalized = []
        for i, name in enumerate(measurement_names):
            if name not in ['height_cm', 'weight_kg']:
                denormalized.append(normalized_measurements[:, i] * self.stds[name] + self.means[name])
        return torch.stack(denormalized, dim=1)

def train_and_evaluate(model, train_loader, test_loader, measurement_float, train_measurement_df, save_dir='/content/drive/MyDrive/bodymeasurement/train/checkpoints_adv2', accumulation_steps=4, resume=False, epochs=200):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # Initialize optimizer, loss functions, and normalizer
    optimizer = get_optimizer(model)
    weighted_loss = WeightedMeasurementLoss([m for m in measurement_float if m not in ['height_cm', 'weight_kg']])
    normalizer = MeasurementNormalizer(train_measurement_df, measurement_float)

    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    log_file = os.path.join(save_dir, 'training_log.csv')
    log_exists = os.path.exists(log_file)

    best_mae = float('inf')
    start_epoch = 0

    checkpoint_path = os.path.join(save_dir, 'latest_checkpoint.pth')
    if resume and os.path.exists(checkpoint_path):
        print("Loading checkpoint...")
        checkpoint = torch.load(checkpoint_path)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_mae = checkpoint['best_mae']
        print(f"Resuming from epoch {start_epoch}")
    else:
        print("Starting training from scratch.")

    print("Starting training...")
    with open(log_file, 'a', newline='') as f:
        writer = csv.writer(f)
        if not log_exists:
            writer.writerow(['Epoch', 'Train Loss', 'Train MAE', 'Test MAE', 'Time'])

        for epoch in range(start_epoch, epochs):
            start_time = time.time()
            model.train()
            train_loss = 0.0
            train_mae = 0.0
            optimizer.zero_grad()

            for batch_idx, (inputs, targets, gender, phone_info) in enumerate(tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")):
                inputs = inputs.to(device)
                targets = targets.to(device)
                gender = gender.to(device)
                phone_info = phone_info.to(device)

                # Normalize targets
                normalized_targets = normalizer.normalize(targets, [m for m in measurement_float if m not in ['height_cm', 'weight_kg']])

                outputs = model(inputs, phone_info, gender)
                loss = weighted_loss(outputs, normalized_targets)
                loss = loss / accumulation_steps
                loss.backward()

                if (batch_idx + 1) % accumulation_steps == 0 or batch_idx + 1 == len(train_loader):
                    optimizer.step()
                    optimizer.zero_grad()

                # Denormalize for MAE calculation
                denormalized_outputs = normalizer.denormalize(outputs, [m for m in measurement_float if m not in ['height_cm', 'weight_kg']])
                train_loss += loss.item() * accumulation_steps
                train_mae += F.l1_loss(denormalized_outputs, targets).item() * accumulation_steps

            avg_train_loss = train_loss / len(train_loader)
            avg_train_mae = train_mae / len(train_loader)

            model.eval()
            test_mae = 0.0
            with torch.no_grad():
                for inputs, targets, gender, phone_info in tqdm(test_loader, desc="Evaluating"):
                    inputs = inputs.to(device)
                    targets = targets.to(device)
                    gender = gender.to(device)
                    phone_info = phone_info.to(device)

                    outputs = model(inputs, phone_info, gender)
                    denormalized_outputs = normalizer.denormalize(outputs, [m for m in measurement_float if m not in ['height_cm', 'weight_kg']])
                    test_mae += F.l1_loss(denormalized_outputs, targets).item()

            current_test_mae = test_mae / len(test_loader)
            epoch_time = time.time() - start_time

            print(f"Epoch {epoch+1}/{epochs}")
            print(f"Train Loss: {avg_train_loss:.4f}, Train MAE: {avg_train_mae:.4f}, Test MAE: {current_test_mae:.4f}")
            print(f"Time: {epoch_time:.2f}s")

            # Log results
            writer.writerow([epoch+1, avg_train_loss, avg_train_mae, current_test_mae, epoch_time])
            f.flush()

            if current_test_mae < best_mae:
                best_mae = current_test_mae
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_mae': best_mae,
                }, os.path.join(save_dir, 'best_model.pth'))
                print(f"New best model saved with MAE: {best_mae:.4f}")

            if (epoch + 1) % 10 == 0:
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_mae': best_mae,
                }, checkpoint_path)
                print(f"Checkpoint saved at epoch {epoch + 1}")

    return best_mae

# Main execution
if __name__ == "__main__":
    # Set device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load and preprocess data
    train_measurement_df, measurement_float = load_and_preprocess_data('/content/drive/MyDrive/bodymeasurement/train/merged_measurements.csv')
    test_measurement_df, _ = load_and_preprocess_data('/content/drive/MyDrive/bodymeasurement/testA/merged_measurements.csv')

    # Define transforms
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    # Load phone dimensions
    phone_dimensions = load_phone_dimensions('/content/drive/MyDrive/bodymeasurement/train/mobile_cleaned_extended_no_nan.csv')

    if not phone_dimensions:
        print("Warning: No valid phone dimensions loaded. Using default values.")
        phone_dimensions = [('Default', 150.0, 75.0, 8.0)]

    # Create datasets
    train_front_img_dir = '/content/drive/MyDrive/bodymeasurement/train/mask'
    train_side_img_dir = '/content/drive/MyDrive/bodymeasurement/train/mask_left'
    test_front_img_dir = '/content/drive/MyDrive/bodymeasurement/testA/mask'
    test_side_img_dir = '/content/drive/MyDrive/bodymeasurement/testA/mask_left'

    print('Creating datasets.....')
    cache_size = 30000
    train_dataset = ConcatenatedImageDataset(train_front_img_dir, train_side_img_dir, train_measurement_df, measurement_float, transform=transform, cache_size=cache_size)
    test_dataset = ConcatenatedImageDataset(test_front_img_dir, test_side_img_dir, test_measurement_df, measurement_float, transform=transform, cache_size=cache_size)

    # Create data loaders
    print("Creating data loaders...")
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, collate_fn=custom_collate)
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2, collate_fn=custom_collate)

    # Create and train the model
    print("Initializing model...")
    num_measurements = len(measurement_float)
    enhanced_resnet101 = EnhancedResNet101(measurement_float).to(device)
    # Load phone dimensions
    phone_dimensions = load_phone_dimensions('/content/drive/MyDrive/bodymeasurement/train/mobile_cleaned.csv')

# Set up the parameters for training
    lr = 0.0005
    weight_decay = 0.0001
    epochs = 200
    save_dir = '/content/drive/MyDrive/bodymeasurement/train/checkpoints_adv3'
    accumulation_steps = 4

best_mae = train_and_evaluate(
    model=enhanced_resnet101,
    train_loader=train_loader,
    test_loader=test_loader,
    measurement_float=measurement_float,
    train_measurement_df=train_measurement_df,  # Add this parameter
    save_dir=save_dir,
    accumulation_steps=accumulation_steps,
    resume=False,
    epochs=200
)

"""Testing the model"""

def test_model(model, test_loader, measurement_float, train_measurement_df):
    """
    Test the model using the same methodology as during training.

    Args:
        model: The trained model
        test_loader: DataLoader for test data
        measurement_float: List of measurement column names
        train_measurement_df: Training DataFrame used for normalization
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    model.eval()

    # Initialize the normalizer with training data
    normalizer = MeasurementNormalizer(train_measurement_df, measurement_float)

    test_mae = 0.0
    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for inputs, targets, gender, phone_info in tqdm(test_loader, desc="Testing"):
            inputs = inputs.to(device)
            targets = targets.to(device)
            gender = gender.to(device)
            phone_info = phone_info.to(device)

            # Get model predictions
            outputs = model(inputs, phone_info, gender)

            # Denormalize predictions for actual measurements
            denormalized_outputs = normalizer.denormalize(outputs, [m for m in measurement_float if m not in ['height_cm', 'weight_kg']])

            # Calculate MAE on denormalized values
            test_mae += F.l1_loss(denormalized_outputs, targets).item()

            # Store predictions and targets for detailed analysis
            all_predictions.extend(denormalized_outputs.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

    # Calculate average MAE
    avg_test_mae = test_mae / len(test_loader)

    # Convert to numpy arrays for analysis
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)

    # Calculate per-measurement MAE
    measurement_names = [m for m in measurement_float if m not in ['height_cm', 'weight_kg']]
    per_measurement_mae = {}
    for i, name in enumerate(measurement_names):
        mae = np.mean(np.abs(all_predictions[:, i] - all_targets[:, i]))
        per_measurement_mae[name] = mae

    print(f"\nOverall Test MAE: {avg_test_mae:.4f}")
    print("\nPer-measurement MAE:")
    for name, mae in per_measurement_mae.items():
        print(f"{name}: {mae:.4f}")

    return avg_test_mae, per_measurement_mae, all_predictions, all_targets

# Load and test the best model
checkpoint_path = os.path.join(save_dir, 'best_model.pth')
checkpoint = torch.load(checkpoint_path)

# Initialize the model
model = EnhancedResNet101(measurement_float).to(device)
model.load_state_dict(checkpoint['model_state_dict'])

# Test the model
mae, per_measurement_mae, predictions, targets = test_model(
    model=model,
    test_loader=test_loader,
    measurement_float=measurement_float,
    train_measurement_df=train_measurement_df
)